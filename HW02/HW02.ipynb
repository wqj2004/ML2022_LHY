{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYlaRwNu7ojq"
   },
   "source": [
    "# **Homework 2 Phoneme Classification**\n",
    "\n",
    "* Slides: https://docs.google.com/presentation/d/1v6HkBWiJb8WNDcJ9_-2kwVstxUWml87b9CnA16Gdoio/edit?usp=sharing\n",
    "* Kaggle: https://www.kaggle.com/c/ml2022spring-hw2\n",
    "* Video: TBA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLQI0mNcmM-O",
    "outputId": "7d5b4d81-9438-4d50-8153-cd235c47ee21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7689.71s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 31 06:44:50 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:04:00.0 Off |                  N/A |\n",
      "| 30%   23C    P8             23W /  350W |     366MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVUGfWTo7_Oj"
   },
   "source": [
    "## Download Data\n",
    "Download data from google drive, then unzip it.\n",
    "\n",
    "You should have\n",
    "- `libriphone/train_split.txt`\n",
    "- `libriphone/train_labels`\n",
    "- `libriphone/test_split.txt`\n",
    "- `libriphone/feat/train/*.pt`: training feature<br>\n",
    "- `libriphone/feat/test/*.pt`:  testing feature<br>\n",
    "\n",
    "after running the following block.\n",
    "\n",
    "> **Notes: if the links are dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2022spring-hw2/data) and upload it to the workspace, or you can use [the Kaggle API](https://www.kaggle.com/general/74235) to directly download the data into colab.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj5jYXsD9Ef3"
   },
   "source": [
    "### Download train/test metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzkiMEcC3Foq",
    "outputId": "cc90c16c-ee21-400e-ec08-dfcd422212a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-31 03:16:07--  https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/463868124/343908dd-b2e4-4b8e-b7d6-7f0f040179ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241031T031608Z&X-Amz-Expires=300&X-Amz-Signature=9f7e2ea2a052abac82ca0b26767ea1fe370b865a3d0851391704c257ff85d50e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlibriphone.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-10-31 03:16:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/463868124/343908dd-b2e4-4b8e-b7d6-7f0f040179ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241031T031608Z&X-Amz-Expires=300&X-Amz-Signature=9f7e2ea2a052abac82ca0b26767ea1fe370b865a3d0851391704c257ff85d50e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlibriphone.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 478737370 (457M) [application/octet-stream]\n",
      "Saving to: ‘libriphone.zip’\n",
      "\n",
      "libriphone.zip        0%[                    ]   1.25M  43.0KB/s    eta 2h 47m ^C\n",
      "[libriphone.zip]\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of libriphone.zip or\n",
      "        libriphone.zip.zip, and cannot find libriphone.zip.ZIP, period.\n",
      "ls: cannot access 'libriphone': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Main link\n",
    "!wget -O libriphone.zip \"https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\"\n",
    "\n",
    "# Backup Link 0\n",
    "# !pip install --upgrade gdown\n",
    "# !gdown --id '1o6Ag-G3qItSmYhTheX6DYiuyNzWyHyTc' --output libriphone.zip\n",
    "\n",
    "# Backup link 1\n",
    "# !pip install --upgrade gdown\n",
    "# !gdown --id '1R1uQYi4QpX0tBfUWt2mbZcncdBsJkxeW' --output libriphone.zip\n",
    "\n",
    "# Backup link 2\n",
    "# !wget -O libriphone.zip \"https://www.dropbox.com/s/wqww8c5dbrl2ka9/libriphone.zip?dl=1\"\n",
    "\n",
    "# Backup link 3\n",
    "# !wget -O libriphone.zip \"https://www.dropbox.com/s/p2ljbtb2bam13in/libriphone.zip?dl=1\"\n",
    "\n",
    "!unzip -q libriphone.zip\n",
    "!ls libriphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L_4anls8Drv"
   },
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "po4N3C-AWuWl"
   },
   "source": [
    "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
    "\n",
    "A phoneme may span several frames and is dependent to past and future frames. \\\n",
    "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
    "\n",
    "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def shift(x, n):\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return torch.cat((left, right), dim=0)\n",
    "\n",
    "x=[[1,2,3],\n",
    "   [4,5,6],\n",
    "   [7,8,9],\n",
    "   [11,12,13],\n",
    "   [14,15,16]\n",
    "   ]\n",
    "x=torch.tensor(x)\n",
    "y=shift(x,-2)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "IJjLT8em-y9G"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_feat(path):\n",
    "    feat = torch.load(path) #把数据变成torch的张量,从而方便处理\n",
    "    return feat\n",
    "\n",
    "def shift(x, n): #把张量x向左/右拓展,n<0就向左拓展,最左边n个都是第0个的复制\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return torch.cat((left, right), dim=0)\n",
    "\n",
    "def concat_feat(x, concat_n): #把张量x做拼接,本来1个,现在和左右相邻的一起扩展成concat_n个输出的向量\n",
    "    assert concat_n % 2 == 1 # n must be odd\n",
    "    if concat_n < 2:\n",
    "        return x\n",
    "    seq_len, feature_dim = x.size(0), x.size(1)\n",
    "    x = x.repeat(1, concat_n) #把x沿着列这个方向重复concat_n次\n",
    "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
    "    mid = (concat_n // 2)\n",
    "    for r_idx in range(1, mid+1):\n",
    "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
    "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
    "\n",
    "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
    "\n",
    "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1337):\n",
    "    # split:数据集的分割类型，可以是 'train'、'val' 或 'test'\n",
    "    # feat_dir：特征文件的目录路径。\n",
    "    # phone_path：存储标签和数据分割信息的路径。\n",
    "    # concat_nframes：用于特征拼接的帧数。\n",
    "    # train_ratio：训练集的比例，默认为 0.8。\n",
    "    # train_val_seed：用于随机种子，以确保训练和验证集的划分是一致的。\n",
    "    class_num = 41 # NOTE: pre-computed, should not need change\n",
    "    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n",
    "\n",
    "    label_dict = {}\n",
    "    if mode != 'test':# 如果不是test,说明有label的信息,就可以把对应的pair放到label_dict中\n",
    "      phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()\n",
    "\n",
    "      for line in phone_file:\n",
    "          line = line.strip('\\n').split(' ')\n",
    "          label_dict[line[0]] = [int(p) for p in line[1:]]\n",
    "\n",
    "    if split == 'train' or split == 'val':\n",
    "        # split training and validation data\n",
    "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
    "        random.seed(train_val_seed)\n",
    "        random.shuffle(usage_list)\n",
    "        percent = int(len(usage_list) * train_ratio)\n",
    "        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:] #train_list用前percent个,val_list用后percent个\n",
    "    elif split == 'test':\n",
    "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
    "    else:\n",
    "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
    "\n",
    "    usage_list = [line.strip('\\n') for line in usage_list] #去掉每一行最后的换行\n",
    "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
    "\n",
    "    max_len = 3000000\n",
    "    X = torch.empty(max_len, 39 * concat_nframes) #X存储各个向量,y存储label\n",
    "    if mode != 'test':\n",
    "      y = torch.empty(max_len, dtype=torch.long)\n",
    "\n",
    "    idx = 0\n",
    "    for i, fname in tqdm(enumerate(usage_list)):\n",
    "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt')) # 每一个feat是一个cur_len个audio向量的序列\n",
    "        cur_len = len(feat)\n",
    "        feat = concat_feat(feat, concat_nframes)\n",
    "        if mode != 'test':\n",
    "          label = torch.LongTensor(label_dict[fname])\n",
    "\n",
    "        X[idx: idx + cur_len, :] = feat\n",
    "        if mode != 'test':\n",
    "          y[idx: idx + cur_len] = label\n",
    "\n",
    "        idx += cur_len\n",
    "\n",
    "    X = X[:idx, :]\n",
    "    if mode != 'test':\n",
    "      y = y[:idx]\n",
    "\n",
    "    print(f'[INFO] {split} set')\n",
    "    print(X.shape)\n",
    "    if mode != 'test':\n",
    "      print(y.shape)\n",
    "      return X, y\n",
    "    else:\n",
    "      return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "us5XW_x6udZQ"
   },
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Fjf5EcmJtf4e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = X\n",
    "        if y is not None:\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRqKNvNZwe3V"
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Bg-GRd7ywdrL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            BasicBlock(input_dim, hidden_dim),\n",
    "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        # *[]就是list的解包操作,对于list而言,就是把两边的方框去掉,比较方便\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlIq8JeqvvHC"
   },
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "iIHn79Iav1ri"
   },
   "outputs": [],
   "source": [
    "# data prarameters\n",
    "concat_nframes = 19              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
    "train_ratio = 0.8               # the ratio of data used for training, the rest will be used for validation\n",
    "\n",
    "# training parameters\n",
    "seed = 0                        # random seed\n",
    "batch_size = 2048                # batch size\n",
    "num_epoch = 50                   # the number of training epoch\n",
    "early_stop=10                   # stop if performance isn't improving\n",
    "learning_rate = 0.0001          # learning rate\n",
    "model_path = './model.ckpt'     # the path where the checkpoint will be saved\n",
    "\n",
    "# model parameters\n",
    "input_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\n",
    "hidden_layers = 4               # the number of hidden layers\n",
    "hidden_dim =1024                # the hidden dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIUFRgG5yoDn"
   },
   "source": [
    "## Prepare dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1zI3v5jyrDn",
    "outputId": "3ea2823a-83f3-42d9-ef05-2f2c002f9538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for train: 3428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3428it [01:12, 47.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train set\n",
      "torch.Size([2116368, 741])\n",
      "torch.Size([2116368])\n",
      "[Dataset] - # phone classes: 41, number of utterances for val: 858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "858it [00:15, 54.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val set\n",
      "torch.Size([527790, 741])\n",
      "torch.Size([527790])\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# preprocess data\n",
    "train_X, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "val_X, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "\n",
    "# get dataset\n",
    "train_set = LibriDataset(train_X, train_y)\n",
    "val_set = LibriDataset(val_X, val_y)\n",
    "\n",
    "# remove raw feature to save memory\n",
    "del train_X, train_y, val_X, val_y\n",
    "gc.collect()\n",
    "\n",
    "# get dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfRUEgC0GxUV",
    "outputId": "f9804711-72b1-4717-896b-821a300cfe87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "88xPiUnm0tAd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#fix seed\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed) #设置torch的随机种子\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)    #为当前GPU设置随机种子\n",
    "        torch.cuda.manual_seed_all(seed)  #为所有可用的GPU设置种子\n",
    "    np.random.seed(seed)  #设置numpy的随机种子\n",
    "    # 下面两行用于确保在使用NVIDIA的CuDNN库时，每次运行的结果都是确定的\n",
    "    torch.backends.cudnn.benchmark = False  #会禁用CuDNN的自动优化功能\n",
    "    torch.backends.cudnn.deterministic = True   #要求CuDNN使用确定性算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTp3ZXg1yO9Y"
   },
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "same_seeds(seed)\n",
    "\n",
    "# create model, define a loss function, and optimizer\n",
    "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)  #创建模型\n",
    "criterion = nn.CrossEntropyLoss()   #设置Loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate*5,weight_decay=0.01)     #设置优化器\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=10, T_mult=2, eta_min=learning_rate/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwWH1KIqzxEr"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdMWsBs7zzNs",
    "outputId": "17922ad2-a319-4253-8783-3e4939d0a7cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:56<00:00, 18.41it/s]\n",
      "100%|██████████| 258/258 [00:09<00:00, 26.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/050] Train Acc: 0.618596 Loss: 1.239789 | Val Acc: 0.677516 loss: 1.023354\n",
      "saving model with acc 0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:59<00:00, 17.45it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/050] Train Acc: 0.678993 Loss: 1.011993 | Val Acc: 0.701832 loss: 0.938215\n",
      "saving model with acc 0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:57<00:00, 18.13it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003/050] Train Acc: 0.702297 Loss: 0.931044 | Val Acc: 0.712560 loss: 0.903445\n",
      "saving model with acc 0.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:51<00:00, 20.14it/s]\n",
      "100%|██████████| 258/258 [00:10<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004/050] Train Acc: 0.717471 Loss: 0.876379 | Val Acc: 0.721255 loss: 0.873552\n",
      "saving model with acc 0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:55<00:00, 18.69it/s]\n",
      "100%|██████████| 258/258 [00:10<00:00, 25.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[005/050] Train Acc: 0.729867 Loss: 0.833178 | Val Acc: 0.727890 loss: 0.854097\n",
      "saving model with acc 0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:52<00:00, 19.70it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[006/050] Train Acc: 0.740061 Loss: 0.797535 | Val Acc: 0.732729 loss: 0.844070\n",
      "saving model with acc 0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:50<00:00, 20.28it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[007/050] Train Acc: 0.748056 Loss: 0.769144 | Val Acc: 0.735802 loss: 0.835255\n",
      "saving model with acc 0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:49<00:00, 21.02it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[008/050] Train Acc: 0.755454 Loss: 0.743343 | Val Acc: 0.738544 loss: 0.828314\n",
      "saving model with acc 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.56it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[009/050] Train Acc: 0.761553 Loss: 0.721043 | Val Acc: 0.740095 loss: 0.826301\n",
      "saving model with acc 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.46it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[010/050] Train Acc: 0.766828 Loss: 0.702153 | Val Acc: 0.742369 loss: 0.824683\n",
      "saving model with acc 0.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.92it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[011/050] Train Acc: 0.771724 Loss: 0.685599 | Val Acc: 0.743171 loss: 0.823677\n",
      "saving model with acc 0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.67it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 32.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[012/050] Train Acc: 0.775817 Loss: 0.670240 | Val Acc: 0.743074 loss: 0.829061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.85it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[013/050] Train Acc: 0.780002 Loss: 0.656964 | Val Acc: 0.744741 loss: 0.826445\n",
      "saving model with acc 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.44it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[014/050] Train Acc: 0.783386 Loss: 0.644153 | Val Acc: 0.744834 loss: 0.829456\n",
      "saving model with acc 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.92it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[015/050] Train Acc: 0.787012 Loss: 0.633190 | Val Acc: 0.745952 loss: 0.829148\n",
      "saving model with acc 0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:53<00:00, 19.46it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[016/050] Train Acc: 0.789840 Loss: 0.622369 | Val Acc: 0.746083 loss: 0.832365\n",
      "saving model with acc 0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:48<00:00, 21.15it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[017/050] Train Acc: 0.792354 Loss: 0.613348 | Val Acc: 0.746763 loss: 0.834536\n",
      "saving model with acc 0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.46it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[018/050] Train Acc: 0.795088 Loss: 0.603793 | Val Acc: 0.746717 loss: 0.834795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.75it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[019/050] Train Acc: 0.797779 Loss: 0.595731 | Val Acc: 0.746882 loss: 0.836349\n",
      "saving model with acc 0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.24it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[020/050] Train Acc: 0.799981 Loss: 0.588387 | Val Acc: 0.747805 loss: 0.835726\n",
      "saving model with acc 0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.29it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[021/050] Train Acc: 0.801638 Loss: 0.581774 | Val Acc: 0.747244 loss: 0.840772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:48<00:00, 21.11it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 31.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[022/050] Train Acc: 0.804077 Loss: 0.573995 | Val Acc: 0.747741 loss: 0.843460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.56it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[023/050] Train Acc: 0.806093 Loss: 0.568011 | Val Acc: 0.747782 loss: 0.843800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.25it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[024/050] Train Acc: 0.807828 Loss: 0.561396 | Val Acc: 0.747886 loss: 0.848981\n",
      "saving model with acc 0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.88it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[025/050] Train Acc: 0.809515 Loss: 0.555616 | Val Acc: 0.749131 loss: 0.848910\n",
      "saving model with acc 0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:49<00:00, 20.93it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[026/050] Train Acc: 0.811178 Loss: 0.550962 | Val Acc: 0.747890 loss: 0.850297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.82it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[027/050] Train Acc: 0.812249 Loss: 0.546887 | Val Acc: 0.747911 loss: 0.855366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.62it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[028/050] Train Acc: 0.813854 Loss: 0.541827 | Val Acc: 0.748423 loss: 0.856412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.64it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[029/050] Train Acc: 0.815348 Loss: 0.536865 | Val Acc: 0.749050 loss: 0.857622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.75it/s]\n",
      "100%|██████████| 258/258 [00:07<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[030/050] Train Acc: 0.816431 Loss: 0.532654 | Val Acc: 0.748781 loss: 0.859952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.39it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[031/050] Train Acc: 0.818174 Loss: 0.527988 | Val Acc: 0.748646 loss: 0.863359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.35it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[032/050] Train Acc: 0.818959 Loss: 0.524444 | Val Acc: 0.748980 loss: 0.861560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.91it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 31.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[033/050] Train Acc: 0.819952 Loss: 0.520715 | Val Acc: 0.748743 loss: 0.865078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.46it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[034/050] Train Acc: 0.821124 Loss: 0.517340 | Val Acc: 0.749321 loss: 0.864834\n",
      "saving model with acc 0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.26it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[035/050] Train Acc: 0.822452 Loss: 0.513632 | Val Acc: 0.749398 loss: 0.868712\n",
      "saving model with acc 0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.20it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[036/050] Train Acc: 0.823533 Loss: 0.509990 | Val Acc: 0.748870 loss: 0.870014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.98it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 31.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[037/050] Train Acc: 0.824408 Loss: 0.507091 | Val Acc: 0.749101 loss: 0.872490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.22it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 28.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[038/050] Train Acc: 0.825712 Loss: 0.503057 | Val Acc: 0.748995 loss: 0.870720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.59it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[039/050] Train Acc: 0.826528 Loss: 0.500405 | Val Acc: 0.748917 loss: 0.872605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.26it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[040/050] Train Acc: 0.827323 Loss: 0.498123 | Val Acc: 0.748889 loss: 0.874612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.06it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[041/050] Train Acc: 0.827953 Loss: 0.495686 | Val Acc: 0.749993 loss: 0.874080\n",
      "saving model with acc 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.63it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[042/050] Train Acc: 0.828939 Loss: 0.492378 | Val Acc: 0.749552 loss: 0.876602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.77it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[043/050] Train Acc: 0.829610 Loss: 0.490724 | Val Acc: 0.749736 loss: 0.873865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.56it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[044/050] Train Acc: 0.830659 Loss: 0.487647 | Val Acc: 0.749654 loss: 0.877503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.47it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 31.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[045/050] Train Acc: 0.831516 Loss: 0.485390 | Val Acc: 0.749097 loss: 0.876753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.87it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 28.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[046/050] Train Acc: 0.832231 Loss: 0.482511 | Val Acc: 0.749783 loss: 0.882804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:47<00:00, 21.90it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[047/050] Train Acc: 0.832895 Loss: 0.480612 | Val Acc: 0.750550 loss: 0.883328\n",
      "saving model with acc 0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.39it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[048/050] Train Acc: 0.833610 Loss: 0.478258 | Val Acc: 0.750118 loss: 0.881094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:46<00:00, 22.15it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 30.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[049/050] Train Acc: 0.834516 Loss: 0.475211 | Val Acc: 0.749258 loss: 0.888664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:45<00:00, 22.93it/s]\n",
      "100%|██████████| 258/258 [00:08<00:00, 29.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[050/050] Train Acc: 0.835044 Loss: 0.474344 | Val Acc: 0.749940 loss: 0.885350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "improve_count=0\n",
    "for epoch in range(num_epoch):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    # training\n",
    "    model.train() # set the model to training mode\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        features, labels = batch\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()           #清除之前的梯度\n",
    "        outputs = model(features)       #pytorch重载了call方法,调用这个实际上是调用的model.forward(features)\n",
    "        \n",
    "        loss = criterion(outputs, labels)   #计算交叉熵损失,其实labels是一个标量,但是无所谓,因为这个分类问题中,实际上labels应该是一个one-hot vector,但是计算的时候相当于只要计算labels对应的那个量就可以了,因为其他的都是0,不算都行.实际上cross-Entropy是每一个都要算的,但由于是one-hot vector,所以可以简化计算\n",
    "        loss.backward()                     #反向传播,计算梯度\n",
    "        optimizer.step()                    #更新模型参数\n",
    "        \n",
    "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # validation\n",
    "    if len(val_set) > 0:\n",
    "        model.eval() # set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(tqdm(val_loader)):\n",
    "                features, labels = batch\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(features)\n",
    "                \n",
    "                loss = criterion(outputs, labels) \n",
    "                \n",
    "                _, val_pred = torch.max(outputs, 1) \n",
    "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
    "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
    "            ))\n",
    "\n",
    "            # if the model improves, save a checkpoint at this epoch\n",
    "            if val_acc > best_acc:\n",
    "                improve_count=0\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
    "            else:\n",
    "                improve_count+=1\n",
    "                if improve_count>=early_stop:\n",
    "                    print(f\"Epoch: {epoch + 1}, model not improving, early stopping.\")\n",
    "                    break\n",
    "    else:\n",
    "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
    "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
    "        ))\n",
    "\n",
    "# if not validating, save the last epoch\n",
    "if len(val_set) == 0:\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print('saving model at last epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab33MxosWLmG",
    "outputId": "911e8c9b-fc0f-4591-b0f6-311a1231c5e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_loader, val_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Hi7jTn3PX-m"
   },
   "source": [
    "## Testing\n",
    "Create a testing dataset, and load model from the saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOG1Ou0PGrhc",
    "outputId": "abaaa25b-a93c-49b0-d228-9eca1e2ab2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1078it [00:23, 46.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test set\n",
      "torch.Size([646268, 741])\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes)\n",
    "test_set = LibriDataset(test_X, None)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ay0Fu8Ovkdad",
    "outputId": "e5b20aa7-4d8b-43a9-e068-f5c89706a360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
    "model.load_state_dict(torch.load(model_path))   #torch.load是加载了模型的参数   model.load是把参数的值对应到torch加载的值上面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84HU5GGjPqR0",
    "outputId": "cebd6694-8f74-44ff-f922-96ca4385acb8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:06<00:00, 51.37it/s]\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "test_lengths = 0\n",
    "pred = np.array([], dtype=np.int32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader)):\n",
    "        features = batch\n",
    "        features = features.to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "\n",
    "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyZqy40Prz0v"
   },
   "source": [
    "Write prediction to a CSV file.\n",
    "\n",
    "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "GuljYSPHcZir"
   },
   "outputs": [],
   "source": [
    "with open('prediction.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, y in enumerate(pred):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML2022Spring - HW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
